# De CSVs heterog√©neos a un almac√©n anal√≠tico confiable  
**Repositorio:** `bigdata-storage-lab-<dedios>`

## Evidencia de funcionamiento

La app desplegada en Streamlit permite cargar CSVs, validarlos y derivar Bronze/Silver:

![App funcionando](docs/captura_app.png)


## 1. Objetivo

Dise√±ar y desplegar un flujo completo de datos que permita transformar **CSVs heterog√©neos** en un **almac√©n anal√≠tico confiable**, siguiendo las etapas:

1. **Ingesta** de archivos CSV de distintas fuentes.  
2. **Validaci√≥n** de esquemas, tipos de datos y reglas de calidad.  
3. **Normalizaci√≥n** y limpieza para unificar formatos y estructuras.  
4. Creaci√≥n de capas **Bronze / Silver** dentro del flujo de almacenamiento.  
   - **Bronze:** datos crudos validados.  
   - **Silver:** datos limpios y estandarizados.  
5. Generaci√≥n de **KPIs** clave en una aplicaci√≥n interactiva (Streamlit).  

El objetivo es demostrar la capacidad de implementar un pipeline reproducible, trazable y documentado, desde datos crudos hasta visualizaciones √∫tiles.

---

## 2. Entregables

- üìÇ **Repositorio GitHub p√∫blico** (`bigdata-storage-lab-<dedios>`) que incluya:  
  - Scripts de ingesta, validaci√≥n y normalizaci√≥n.  
  - Estructura de carpetas (bronze, silver).  
  - Notebook(s) de prueba y ejemplos de ejecuci√≥n.  
  - Documentaci√≥n clara en Markdown.  

- üñ•Ô∏è **Aplicaci√≥n Streamlit**:  
  - Lectura de datos desde la capa *Silver*.  
  - C√°lculo de al menos **3 KPIs relevantes**.  
  - Visualizaci√≥n interactiva (tablas, gr√°ficos, filtros).  

---

## 3. Criterios de Evaluaci√≥n

1. **Dise√±o y justificaci√≥n t√©cnica**  
   - Claridad en la arquitectura del pipeline.  
   - Razonamiento detr√°s de elecciones tecnol√≥gicas y de modelado.  

2. **Calidad de datos**  
   - Reglas de validaci√≥n implementadas.  
   - Manejo de valores nulos, duplicados, inconsistencias.  

3. **Trazabilidad y dise√±o del Data Warehouse**  
   - Evidencia clara de transici√≥n entre capas (Bronze ‚Üí Silver).  
   - Organizaci√≥n modular y reproducible.  

4. **Documentaci√≥n**  
   - README inicial completo.  
   - Gu√≠as de ejecuci√≥n reproducibles.  
   - Comentarios adecuados en el c√≥digo.  

---

## 4. Qu√© NO subir

üö´ **No incluir datos sensibles o privados**.  
- Usa datos sint√©ticos, abiertos o anonimizados.  
- No exponer credenciales, tokens ni configuraciones locales de seguridad.  

---

## 5. Tiempo estimado por fase

| Fase                          | Tiempo estimado |
|-------------------------------|-----------------|
| Ingesta de CSVs               | 2 h             |
| Validaci√≥n de datos           | 3 h             |
| Normalizaci√≥n y limpieza      | 4 h             |
| Definici√≥n Bronze / Silver    | 3 h             |
| Desarrollo KPIs (Streamlit)   | 4 h             |
| Documentaci√≥n y README final  | 2 h             |
| **Total**                     | **18 h aprox.** |

## 6. Decisiones de dise√±o (5V)

- **Volumen**: Los CSV son medianos ‚Üí se procesan con pandas; se usan capas Bronze/Silver para manejar escalabilidad.
- **Velocidad**: Procesamiento batch en memoria; Streamlit da resultados inmediatos.
- **Variedad**: Los CSV traen columnas distintas ‚Üí se usa un mapeo origen‚Üícan√≥nico y normalizaci√≥n de fechas/amount.
- **Veracidad**: Validaciones implementadas (`basic_checks`), linaje (`source_file`, `ingested_at`).
- **Valor**: Agregaci√≥n en Silver (partner √ó mes), KPIs y gr√°fico ‚Üí insights claros.
## 7üìù Prompts de reflexi√≥n (con respuestas modelo)

1. **V dominante hoy y V dominante si 2√ó tr√°fico**  
   Hoy la **Variedad** es la V dominante: recibimos CSVs con columnas y formatos distintos que requieren normalizaci√≥n.  
   Si el tr√°fico se duplicara, la **Velocidad** ser√≠a dominante, porque el reto pasar√≠a a ser procesar los archivos en menos tiempo sin colapsar la app.  
   La arquitectura tendr√≠a que optimizar el pipeline para mantener la experiencia fluida.

2. **Trade-off elegido (ej.: m√°s compresi√≥n vs CPU)**  
   Se prioriz√≥ **guardar los CSV normalizados sin compresi√≥n**, para ahorrar CPU en la app y reducir la latencia al descargar.  
   El trade-off es ocupar m√°s espacio en disco, pero mediremos este impacto revisando el tama√±o acumulado de `/data/bronze` y `/data/silver`.  
   Si el crecimiento fuera excesivo, se evaluar√° un formato columnar (Parquet) con compresi√≥n ligera.

3. **Por qu√© ‚Äúinmutable + linaje‚Äù mejora veracidad y qu√© coste a√±ade**  
   Mantener los datos inmutables y con **linaje (`source_file`, `ingested_at`)** asegura que podemos auditar cualquier KPI hasta su origen.  
   Esto mejora la **veracidad**, porque cada cifra tiene trazabilidad completa.  
   El coste a√±adido es m√°s almacenamiento (cada ingesta conserva duplicados) y mayor complejidad en la gesti√≥n de metadatos.

4. **KPI principal y SLA del dashboard**  
   - **KPI**: Total de ventas mensuales por partner.  
   - **SLA (latencia)**: actualizaci√≥n en menos de **1 minuto** tras subir un nuevo CSV.  
   - Esto habilita decisiones r√°pidas de negocio (ej. detectar partners m√°s activos en el mes) y justifica que la latencia sea baja: la app debe ser interactiva, no batch.

5. **Riesgo principal del dise√±o y mitigaci√≥n t√©cnica concreta**  
   Riesgo: **errores de parseo en fechas/amount** al recibir CSVs con formatos inesperados.  
   Mitigaci√≥n: usar `pd.to_datetime(errors="coerce")` y normalizaci√≥n de montos en `normalize_columns`, adem√°s de reportar validaciones fallidas en pantalla.  
   Con esto evitamos que un archivo corrupto bloquee el pipeline y damos feedback inmediato al usuario.




üìå **Recomendaci√≥n:** trabajar por ramas (`feature/ingesta`, `feature/streamlit`, etc.) y hacer *pull requests* revisables.  

