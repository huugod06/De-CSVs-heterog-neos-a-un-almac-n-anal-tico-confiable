# De CSVs heterog√©neos a un almac√©n anal√≠tico confiable  
**Repositorio:** `bigdata-storage-lab-<dedios>`

---

## 1. Objetivo

Dise√±ar y desplegar un flujo completo de datos que permita transformar **CSVs heterog√©neos** en un **almac√©n anal√≠tico confiable**, siguiendo las etapas:

1. **Ingesta** de archivos CSV de distintas fuentes.  
2. **Validaci√≥n** de esquemas, tipos de datos y reglas de calidad.  
3. **Normalizaci√≥n** y limpieza para unificar formatos y estructuras.  
4. Creaci√≥n de capas **Bronze / Silver** dentro del flujo de almacenamiento.  
   - **Bronze:** datos crudos validados.  
   - **Silver:** datos limpios y estandarizados.  
5. Generaci√≥n de **KPIs** clave en una aplicaci√≥n interactiva (Streamlit).  

El objetivo es demostrar la capacidad de implementar un pipeline reproducible, trazable y documentado, desde datos crudos hasta visualizaciones √∫tiles.

---

## 2. Entregables

- üìÇ **Repositorio GitHub p√∫blico** (`bigdata-storage-lab-<dedios>`) que incluya:  
  - Scripts de ingesta, validaci√≥n y normalizaci√≥n.  
  - Estructura de carpetas (bronze, silver).  
  - Notebook(s) de prueba y ejemplos de ejecuci√≥n.  
  - Documentaci√≥n clara en Markdown.  

- üñ•Ô∏è **Aplicaci√≥n Streamlit**:  
  - Lectura de datos desde la capa *Silver*.  
  - C√°lculo de al menos **3 KPIs relevantes**.  
  - Visualizaci√≥n interactiva (tablas, gr√°ficos, filtros).  

---

## 3. Criterios de Evaluaci√≥n

1. **Dise√±o y justificaci√≥n t√©cnica**  
   - Claridad en la arquitectura del pipeline.  
   - Razonamiento detr√°s de elecciones tecnol√≥gicas y de modelado.  

2. **Calidad de datos**  
   - Reglas de validaci√≥n implementadas.  
   - Manejo de valores nulos, duplicados, inconsistencias.  

3. **Trazabilidad y dise√±o del Data Warehouse**  
   - Evidencia clara de transici√≥n entre capas (Bronze ‚Üí Silver).  
   - Organizaci√≥n modular y reproducible.  

4. **Documentaci√≥n**  
   - README inicial completo.  
   - Gu√≠as de ejecuci√≥n reproducibles.  
   - Comentarios adecuados en el c√≥digo.  

---

## 4. Qu√© NO subir

üö´ **No incluir datos sensibles o privados**.  
- Usa datos sint√©ticos, abiertos o anonimizados.  
- No exponer credenciales, tokens ni configuraciones locales de seguridad.  

---

## 5. Tiempo estimado por fase

| Fase                          | Tiempo estimado |
|-------------------------------|-----------------|
| Ingesta de CSVs               | 2 h             |
| Validaci√≥n de datos           | 3 h             |
| Normalizaci√≥n y limpieza      | 4 h             |
| Definici√≥n Bronze / Silver    | 3 h             |
| Desarrollo KPIs (Streamlit)   | 4 h             |
| Documentaci√≥n y README final  | 2 h             |
| **Total**                     | **18 h aprox.** |

## 6. Decisiones de dise√±o (5V)

- **Volumen**: Los CSV son medianos ‚Üí se procesan con pandas; se usan capas Bronze/Silver para manejar escalabilidad.
- **Velocidad**: Procesamiento batch en memoria; Streamlit da resultados inmediatos.
- **Variedad**: Los CSV traen columnas distintas ‚Üí se usa un mapeo origen‚Üícan√≥nico y normalizaci√≥n de fechas/amount.
- **Veracidad**: Validaciones implementadas (`basic_checks`), linaje (`source_file`, `ingested_at`).
- **Valor**: Agregaci√≥n en Silver (partner √ó mes), KPIs y gr√°fico ‚Üí insights claros.


üìå **Recomendaci√≥n:** trabajar por ramas (`feature/ingesta`, `feature/streamlit`, etc.) y hacer *pull requests* revisables.  

